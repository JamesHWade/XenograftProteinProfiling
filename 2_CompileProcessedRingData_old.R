GetName <- function(){
	# get the filename from the current working directory
	directory <- basename(getwd())

	# directory naming from MRR: "CHIPNAME_gaskGASETTYPE_DATE"
	# extracts and returns GASKETTYPE from directory name
	name <- unlist(strsplit(directory, split = "_"))
	name <- name[2]

	# define name as global variable for use in other functions
	name <<- gsub('gask','',name) # removes "gask" from name
}

CompileData <- function(){
	# load relevant libraries
	library(readr)

	# get working directory to reset at end of function
	directory <- getwd()
	
	# generate list of runs and empty data frame
	listData <- list.dirs(recursive = FALSE) # gets list for top level dirs
	df <- data.frame()

	# iterates through each directory (i.e., run)
	for (i in 1:length(listData)){
		tempDir <- listData[i]
		setwd(tempDir)
		names <- GetName()
		# uses "corrected" data (outliers removed) if it exists
		if (file.exists('corrected/')){
			dat <- read_csv(paste("corrected/", names, 
				"_avgShifts.csv", sep=""), col_types = cols())
		} else {
			dat <- read_csv(paste("plots/", names, 
				"_avgShifts.csv", sep=""), col_types = cols())
	}
		dat$run <- names # adds run name to data frame
		df <- rbind(df, dat) # combines runs into single data frame
		setwd(directory) #returns working dir to starting dir
	}
	
	# saves data
	write_csv(df, 'compiledData.csv')
}

CleanData <- function(filename = 'runs.csv'){
	# load relevant libraries
	library(dplyr)
	library(readr)

	# gets run information, this file was manually created
	dat.info <- read_csv(filename, col_types = cols())
	
	# generates list of treatments and removes NA data and blank runs
	treatments <- unique(dat.info$Treatment, na.rm = TRUE)
	remove <- c(NA, 'NA', 'Blank')    
	treatments <- treatments[!treatments %in% remove]
	
	# gets compiled data generated by CompileData function
	dat <- read_csv('compiledData.csv', col_types = cols())
	
	# chID <- unique(dat$Target) # useful if U-channel experiment
	# splits targets into ch1 & ch2 (this is an inelegant solution)
	ch1 <- c("thermal", "p-c-Abl_ch1", "p-PDK1_ch1", "p-GSK3b_ch1", 
		"p-p70S6K_ch1", "p-S6_235_ch1", "p-Rb_780_ch1", "p-Akt_308_ch1", 
		"p-S6_240_ch1", "p-Rb_807_ch1", "p-mTOR_ch1", "p-MAPK_ch1", 
		"p-Akt_473_ch1", "p-p53_ch1", "p-Src_ch1", "hydroxy-HIF_ch1")
	ch2 <- c("p-c-Abl_ch2", "p-PDK1_ch2", "p-GSK3b_ch2", "p-p70S6K_ch2",
		"p-S6_235_ch2", "p-Rb_780_ch2", "p-Akt_308_ch2", "p-S6_240_ch2",
		"p-Rb_807_ch2", "p-mTOR_ch2", "p-MAPK_ch2", "p-Akt_473_ch2",
		"p-p53_ch2", "p-Src_ch2", "hydroxy-HIF_ch2")
	
	# creates empty data frame to store labeled data
	df <- data.frame()
	
	# iterates through each row in compiled data
	# assigns to data to by channel
	for(i in 1:nrow(dat)){
		dat.row <- dat[i, ]
		if (dat.row$Target %in% ch1){
			runInfo <- filter(dat.info, Runs == 
				dat.row$run & Channel == 'Ch1')
		} else {
			runInfo <- filter(dat.info, Runs == 
				dat.row$run & Channel == 'Ch2')
		}
		tmp <- cbind(dat.row, runInfo)
		df <- rbind(df, tmp)
	}
	
	df$run <- NULL # removes run name (e.g., XPP-001a)
	df <- df[complete.cases(df),] # removes any incomplete data (e.g., NAs)
	
	# saves data
	write_csv(df, "compiledLabeled.csv")
}

CombinedAveraged <- function(filename = "compiledLabeled.csv"){
	# load relevant libraries
	library(readr)
	library(dplyr)
	
	# get labeled data
	dat <- read_csv(filename, col_types = cols())
	
	# remove channel designation from target
	dat$Target <- gsub('_ch1', '', dat$Target)
	dat$Target <- gsub('_ch2', '', dat$Target)
	
	# generate lists for targets, cell line, time points, and treatments
	targets <- unique(dat$Target)
	cellLine <- unique(dat$`Cell Line`)
	timePoint <- unique(dat$`Time Point`)
	treatment <- unique(dat$Treatment)
	
	# calculate lengths to create matrix for subsequent data averaging
	len.tot <- length(targets) * length(cellLine) * length(treatment) * 
		length(timePoint)
	len.targets <- len.tot / length(targets)
	len.cellLine <- len.tot / length(cellLine)
	len.treatment <- len.tot / length(treatment)
	len.timePoint <- len.tot / length(timePoint)
	
	# create vectors for matrix for subsequent data averaging
	targets <- rep(targets, len.targets)
	timePoint <- rep(timePoint, each = len.timePoint)
	cellLine <- rep(cellLine, len.cellLine)
	treatment <- rep(treatment, each = len.treatment)
	
	# combine vectors to create matrix for data averaging
	allGroups <- cbind(targets, timePoint, cellLine, treatment)
	allGroups <- as.data.frame(allGroups)
	
	# generate emtpy data frame to store data
	df <- data.frame()

	# iterate through each row of matrix to average data
	for(i in 1:nrow(allGroups)){
		id.tar <- unlist(allGroups[i,1])
		id.time <- allGroups[i,2]
		id.cell <- allGroups[i,3]
		id.treat <- unlist(allGroups[i,4])
		# filter data based on according to matrix
		dat.group <- filter(dat, Target == id.tar, `Cell Line` == 
			id.cell & `Time Point` == id.time & Treatment == id.treat)
		# average filtered data
		dat.shifts <- dat.group$`Average Shift`
		avgShift <- mean(dat.shifts)
		sdShift <- sd(dat.shifts)
		seShift <- sd(dat.shifts) / sqrt(length(dat.shifts))
		cvShift <- sd(dat.shifts) / avgShift * 100
		target <- unique(dat.group$groupName)
		tmp <- data.frame(id.tar, id.cell, id.time, avgShift, 
			sdShift, seShift, cvShift, id.treat)
		df <- rbind(df, tmp)
	}

	# rename columns of data frame
	names(df) <- c("Target", "Cell Line", "Time Point", "Average Shift", 
		"SD", "SE", "CV", "Treatment")
	
	# saves data
	write_csv(df, "Combined_Averaged.csv")
}

GoCompile <- function(){
	CompileData()
	CleanData()
	CombinedAveraged()
}
    