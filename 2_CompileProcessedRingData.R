# Aggregate net shift data into single data file
CompileData <- function(){
        # load relevant libraries
        library(tidyverse)

        # generate list of runs and empty data frame
        filesList <- list.files(recursive = TRUE, pattern = ".csv")
        netList <- filesList[grepl("net", filesList)]
        
        # iterates through each directory (i.e., run)
        df <- lapply(netList, function(i){
                names <- strsplit(basename(i), split = "_")[[1]][1]
                dat <- read_csv(i)
                dat$Run <- names # adds run name to data frame
                dat
        })
        df <- bind_rows(df)
        
        # saves data
        write_csv(df, 'compiledData.csv')
}

# Annotate aggregated net shift data with run information
CleanData <- function(filename = 'runs.csv'){
        # load relevant libraries
        library(tidyverse)
        
        # gets run information, this file was manually created
        dat.info <- read_csv(filename)
        
        # generates list of treatments and removes NA data and blank runs
        treatments <- unique(dat.info$Treatment, na.rm = TRUE)
        remove <- c(NA, 'NA', 'Blank')    
        treatments <- treatments[!treatments %in% remove]
        
        # gets compiled data generated by CompileData function
        dat <- read_csv('compiledData.csv')
        # cname <- colnames(dat)
        
        # iterates through each row in compiled data
        # assigns to data to by channel
        df <- apply(dat, 1, function(i){
                a <- filter(dat.info, Runs == i[6] & Channel == i[7])
        })
        
        df <- bind_rows(df)
        df$Channel <- NULL # remove redundant column
        df <- cbind(dat, df)
        
        # remove any NAs, Blank runs, and thermal rings
        df <- df[complete.cases(df),]
        df <- filter(df, Treatment != "Blank" & Target != "thermal")
        
        # remove reduntant columns
        df$run <- NULL
        df$Step <- NULL
        df$Runs <- NULL
        df$Run <- NULL
        df$Shift.1 <- NULL
        df$Shift.2 <- NULL
        
        # saves data
        write_csv(df, "compiledLabeled.csv")
}

NormalizeData <- function(i){
        library(tidyverse)
        library(reshape2)
        
        setwd("D:/Box Sync/Data/")
        dat <- read_csv("compiledLabeled.csv")
        dat <- dat %>% mutate(n = Ring %% 4,
                              LogTransformed = log(NetShift))
        dat <- filter(dat, Replicate != 1)
        
        datScaled <- dat %>%
                group_by(Target) %>%
                mutate(NormLog = scale(LogTransformed),
                       Normalized = scale(NetShift))
        
        cv <- function(x){sd(x)/mean(x) * 100}
        datSum <- datScaled %>%
                group_by(Target, CellLine, Treatment, TimePoint) %>%
                summarize_at(vars("NetShift", "Normalized", 
                                  "NormLog", "LogTransformed"),
                             funs(mean, sd, cv, length))
        
        write_csv(datScaled, "compiledNormalized.csv")
        write_csv(datSum, "compiledSummed.csv")
}

# Single function to run both functions above
CompileAndProcess <- function(){
        CompileData()
        CleanData()
        NormalizeData()
}
